{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "moving-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime \n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "absolute-lyric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hearing-favorite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices(device_type = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "legislative-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "f16 = pd.read_csv('data/f16_l3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a49c67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = f16['Force']\n",
    "y = f16['Acceleration3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afc2818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = MinMaxScaler().fit_transform(X.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "874b8b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare the number of model iterations we will run \n",
    "test_iterations = 5\n",
    "\n",
    "#Declare the size of the initial train test split\n",
    "test_size = 0.20\n",
    "\n",
    "#Declare the number of hidden layers to add\n",
    "layers = 2\n",
    "\n",
    "#Declare the density of the hidden layers\n",
    "density = 128\n",
    "\n",
    "#Declare the type of activation for the hidden layers\n",
    "activation = tf.keras.layers.LSTM\n",
    "\n",
    "#Assign the loss function the model will use to train\n",
    "loss = 'mean_squared_error'\n",
    "\n",
    "#Assign the optimizer for the compilitation\n",
    "optimizer = 'adam'\n",
    "\n",
    "#Declare the patience count used for early stopping\n",
    "patience = 25\n",
    "\n",
    "#Declare the test size used for early stopping train test split\n",
    "es_test_size = 0.25\n",
    "\n",
    "#Declare the batch size for use in the model\n",
    "batch_size = 64\n",
    "\n",
    "#Declare the maximum number of epochs for our model\n",
    "epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df96ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_true, y_train, y_true = train_test_split(\n",
    "    X, y, random_state = 8669, test_size = test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71d1a13d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_sequence_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-44d7d7aa2df3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpadded_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_sequence_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpadded_inputs_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_sequence_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'max_sequence_length' is not defined"
     ]
    }
   ],
   "source": [
    "padded_inputs = pad_sequences(X_train, maxlen = max_sequence_length, value = 0.0)\n",
    "padded_inputs_test = pad_sequences(X_test, maxlen = max_sequence_length, value = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bronze-cleaner",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_distinct_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-9300f7beda6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_distinct_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_output_dims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_sequence_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#Creates a for loop that will add the number of layers based on the variable declared in the previous cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_distinct_words' is not defined"
     ]
    }
   ],
   "source": [
    "#Assigns the computation to be performed via GPU Device:0\n",
    "with tf.device('/gpu:0'):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(num_distinct_words, embedding_output_dims, input_length=max_sequence_length))\n",
    "    \n",
    "    #Creates a for loop that will add the number of layers based on the variable declared in the previous cell    \n",
    "    for i in range(layers):\n",
    "        #Adds a model layer with density and activation based on the variables declared in the previous cell\n",
    "        model.add(activation(density))\n",
    "    \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    #model.compile(loss = loss, optimizer = optimizer, metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "detailed-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'loss', patience = patience, restore_best_weights = True)\n",
    "mc = ModelCheckpoint(filepath = 'test_model.h5', monitor = 'loss', save_best_only=True)\n",
    "X_es_train, X_es_true, y_es_train, y_es_true = train_test_split(X_train, y_train, test_size = es_test_size, random_state = 8669)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7cdf4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a dataframe by which we will eventually put in our list created above\n",
    "model_record = pd.DataFrame(columns = ['model_num', 'loss_type', 'time', 'epochs', 'r2', 'mae', 'mse', 'rmse', 'max_error'])\n",
    "\n",
    "#Creates a dataframe by which our model's predicted values and true values will be stored\n",
    "predict_record = pd.DataFrame(y_true).reset_index(drop = True)\n",
    "\n",
    "#Creates a numpy array by which the for loop will use to count model runs and is then used to name df columns\n",
    "model_counter = np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "098002c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 train_step\n        y_pred = self(x, training=True)\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:215 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-c4445b090d36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m#          batch_size = batch_size, epochs = epochs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         history = model.fit(x = X_es_train, y = y_es_train.values, \n\u001b[0m\u001b[0;32m     20\u001b[0m                   \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_es_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_es_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                   \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 train_step\n        y_pred = self(x, training=True)\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:215 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 1)\n"
     ]
    }
   ],
   "source": [
    "#Assigns the computation to be performed via GPU Device:0\n",
    "with tf.device('/gpu:0'):\n",
    "    \n",
    "#Performs model training repeatedly based on the variable declared previously    \n",
    "    for i in range(test_iterations):\n",
    "        model.compile(loss = loss, optimizer = optimizer, metrics = ['mse'])\n",
    "\n",
    "        #Creates an empty list for storing model metrics and other information \n",
    "        record_list = list() \n",
    "        #Starts a counter that adds 1 everytime a fitting is performed\n",
    "        model_counter = model_counter + 1\n",
    "        #Starts a timer to end after the round of fitting is complete\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        #Fits our model/batch_size and epochs are declared previously\n",
    "        #model.fit(x = X_train, y = y_train.values, \n",
    "        #          batch_size = batch_size, epochs = epochs)\n",
    "        \n",
    "        history = model.fit(x = X_es_train, y = y_es_train.values, \n",
    "                  validation_data = (X_es_true, y_es_true),\n",
    "                  batch_size = batch_size, epochs = epochs, \n",
    "                  callbacks = [es, mc])\n",
    "        \n",
    "        #Saves our model predictions\n",
    "        y_pred = model.predict(X_true)\n",
    "        \n",
    "        #Saves our model run #, time to run, and model metrics to our temporary list\n",
    "        record_list.extend([len(model_record)+1, #A model iteration count\n",
    "                            loss, #Records the loss metric used to fit the model\n",
    "                            format(datetime.now() - start_time), #Calculates the time it took to complete the model\n",
    "                            len(history.history['loss']), #The epoch number of our model checkpoint \n",
    "                            r2_score(y_true, y_pred), #R2\n",
    "                            mean_absolute_error(y_true, y_pred), #MAE\n",
    "                            mean_squared_error(y_true, y_pred), #MSE\n",
    "                            np.sqrt(mean_squared_error(y_true, y_pred)), #RMSE\n",
    "                            max_error(y_true, y_pred) #MaxError\n",
    "                           ])        \n",
    "        \n",
    "        #Adds the temporary list of model metrics (etc) to the end of a dataframe\n",
    "        model_record.loc[len(model_record)] = record_list\n",
    "        \n",
    "        #Converts our predictions to a dataframe so it will play nice\n",
    "        y_pred_df = pd.DataFrame(y_pred)\n",
    "        \n",
    "        #Adds predictions as a column to the end of a dataframe and names is accordingly\n",
    "        predict_record = pd.concat([predict_record, y_pred_df], axis = 1)\n",
    "        predict_record = predict_record.rename(columns = {0 : 'm' + str(model_counter[0])})\n",
    "        \n",
    "        #Calculates the residual values for each prediction and stores it as a dataframe \n",
    "        residuals_df = pd.DataFrame(abs(predict_record.iloc[:,len(predict_record.columns)-1] - predict_record.iloc[:,0]))\n",
    "        \n",
    "        #Adds y residuals as a column to the end of a dataframe and names is accordingly\n",
    "        predict_record = pd.concat([predict_record, residuals_df], axis = 1)\n",
    "        predict_record = predict_record.rename(columns = {0 : 'res' + str(model_counter[0])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "affa6aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_num</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>time</th>\n",
       "      <th>epochs</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>max_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:06:58.600213</td>\n",
       "      <td>133</td>\n",
       "      <td>0.186559</td>\n",
       "      <td>0.231756</td>\n",
       "      <td>0.217424</td>\n",
       "      <td>0.466287</td>\n",
       "      <td>5.227035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:01:52.498483</td>\n",
       "      <td>36</td>\n",
       "      <td>0.181425</td>\n",
       "      <td>0.232965</td>\n",
       "      <td>0.218796</td>\n",
       "      <td>0.467756</td>\n",
       "      <td>5.223996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:02:09.278538</td>\n",
       "      <td>41</td>\n",
       "      <td>0.188748</td>\n",
       "      <td>0.231858</td>\n",
       "      <td>0.216839</td>\n",
       "      <td>0.465659</td>\n",
       "      <td>5.197324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:05:06.451410</td>\n",
       "      <td>97</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.229295</td>\n",
       "      <td>0.216638</td>\n",
       "      <td>0.465444</td>\n",
       "      <td>5.207352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:04:46.452250</td>\n",
       "      <td>92</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.228036</td>\n",
       "      <td>0.215824</td>\n",
       "      <td>0.464569</td>\n",
       "      <td>5.226808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>246</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:02:03.743139</td>\n",
       "      <td>50</td>\n",
       "      <td>0.191273</td>\n",
       "      <td>0.230419</td>\n",
       "      <td>0.216164</td>\n",
       "      <td>0.464934</td>\n",
       "      <td>5.230475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>247</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:02:23.196040</td>\n",
       "      <td>58</td>\n",
       "      <td>0.192038</td>\n",
       "      <td>0.227559</td>\n",
       "      <td>0.215959</td>\n",
       "      <td>0.464714</td>\n",
       "      <td>5.246212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:01:34.966605</td>\n",
       "      <td>38</td>\n",
       "      <td>0.191216</td>\n",
       "      <td>0.230462</td>\n",
       "      <td>0.216179</td>\n",
       "      <td>0.464951</td>\n",
       "      <td>5.216463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>249</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:01:11.746546</td>\n",
       "      <td>29</td>\n",
       "      <td>0.184985</td>\n",
       "      <td>0.233981</td>\n",
       "      <td>0.217844</td>\n",
       "      <td>0.466738</td>\n",
       "      <td>5.217321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>250</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:02:08.018930</td>\n",
       "      <td>52</td>\n",
       "      <td>0.191255</td>\n",
       "      <td>0.230279</td>\n",
       "      <td>0.216169</td>\n",
       "      <td>0.464939</td>\n",
       "      <td>5.218469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_num           loss_type            time epochs        r2       mae  \\\n",
       "0           1  mean_squared_error  0:06:58.600213    133  0.186559  0.231756   \n",
       "1           2  mean_squared_error  0:01:52.498483     36  0.181425  0.232965   \n",
       "2           3  mean_squared_error  0:02:09.278538     41  0.188748  0.231858   \n",
       "3           4  mean_squared_error  0:05:06.451410     97  0.189500  0.229295   \n",
       "4           5  mean_squared_error  0:04:46.452250     92  0.192543  0.228036   \n",
       "..        ...                 ...             ...    ...       ...       ...   \n",
       "245       246  mean_squared_error  0:02:03.743139     50  0.191273  0.230419   \n",
       "246       247  mean_squared_error  0:02:23.196040     58  0.192038  0.227559   \n",
       "247       248  mean_squared_error  0:01:34.966605     38  0.191216  0.230462   \n",
       "248       249  mean_squared_error  0:01:11.746546     29  0.184985  0.233981   \n",
       "249       250  mean_squared_error  0:02:08.018930     52  0.191255  0.230279   \n",
       "\n",
       "          mse      rmse  max_error  \n",
       "0    0.217424  0.466287   5.227035  \n",
       "1    0.218796  0.467756   5.223996  \n",
       "2    0.216839  0.465659   5.197324  \n",
       "3    0.216638  0.465444   5.207352  \n",
       "4    0.215824  0.464569   5.226808  \n",
       "..        ...       ...        ...  \n",
       "245  0.216164  0.464934   5.230475  \n",
       "246  0.215959  0.464714   5.246212  \n",
       "247  0.216179  0.464951   5.216463  \n",
       "248  0.217844  0.466738   5.217321  \n",
       "249  0.216169  0.464939   5.218469  \n",
       "\n",
       "[250 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "welsh-posting",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acceleration3</th>\n",
       "      <th>m1</th>\n",
       "      <th>res1</th>\n",
       "      <th>m2</th>\n",
       "      <th>res2</th>\n",
       "      <th>m3</th>\n",
       "      <th>res3</th>\n",
       "      <th>m4</th>\n",
       "      <th>res4</th>\n",
       "      <th>m5</th>\n",
       "      <th>...</th>\n",
       "      <th>m246</th>\n",
       "      <th>res246</th>\n",
       "      <th>m247</th>\n",
       "      <th>res247</th>\n",
       "      <th>m248</th>\n",
       "      <th>res248</th>\n",
       "      <th>m249</th>\n",
       "      <th>res249</th>\n",
       "      <th>m250</th>\n",
       "      <th>res250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.314890</td>\n",
       "      <td>-0.106363</td>\n",
       "      <td>0.208527</td>\n",
       "      <td>-0.107560</td>\n",
       "      <td>0.207330</td>\n",
       "      <td>-0.080738</td>\n",
       "      <td>0.234152</td>\n",
       "      <td>-0.092641</td>\n",
       "      <td>0.222249</td>\n",
       "      <td>-0.106148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088585</td>\n",
       "      <td>0.226305</td>\n",
       "      <td>-0.128249</td>\n",
       "      <td>0.186641</td>\n",
       "      <td>-0.079163</td>\n",
       "      <td>0.235727</td>\n",
       "      <td>-0.079369</td>\n",
       "      <td>0.235521</td>\n",
       "      <td>-0.078189</td>\n",
       "      <td>0.236701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.267150</td>\n",
       "      <td>-0.335971</td>\n",
       "      <td>0.068821</td>\n",
       "      <td>-0.416756</td>\n",
       "      <td>0.149606</td>\n",
       "      <td>-0.308923</td>\n",
       "      <td>0.041773</td>\n",
       "      <td>-0.328997</td>\n",
       "      <td>0.061847</td>\n",
       "      <td>-0.291686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.261380</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>-0.283757</td>\n",
       "      <td>0.016607</td>\n",
       "      <td>-0.262028</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>-0.312943</td>\n",
       "      <td>0.045793</td>\n",
       "      <td>-0.260745</td>\n",
       "      <td>0.006405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.257710</td>\n",
       "      <td>0.242710</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.289920</td>\n",
       "      <td>0.032210</td>\n",
       "      <td>0.337488</td>\n",
       "      <td>0.079778</td>\n",
       "      <td>0.250313</td>\n",
       "      <td>0.007397</td>\n",
       "      <td>0.272763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325091</td>\n",
       "      <td>0.067381</td>\n",
       "      <td>0.252545</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>0.331247</td>\n",
       "      <td>0.073537</td>\n",
       "      <td>0.394625</td>\n",
       "      <td>0.136915</td>\n",
       "      <td>0.320211</td>\n",
       "      <td>0.062501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.193330</td>\n",
       "      <td>-0.102681</td>\n",
       "      <td>0.090649</td>\n",
       "      <td>-0.100139</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>-0.074237</td>\n",
       "      <td>0.119093</td>\n",
       "      <td>-0.085076</td>\n",
       "      <td>0.108254</td>\n",
       "      <td>-0.104071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108305</td>\n",
       "      <td>0.085025</td>\n",
       "      <td>-0.124479</td>\n",
       "      <td>0.068851</td>\n",
       "      <td>-0.093893</td>\n",
       "      <td>0.099437</td>\n",
       "      <td>-0.094721</td>\n",
       "      <td>0.098609</td>\n",
       "      <td>-0.095860</td>\n",
       "      <td>0.097470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.409560</td>\n",
       "      <td>-0.135525</td>\n",
       "      <td>0.274035</td>\n",
       "      <td>-0.139184</td>\n",
       "      <td>0.270376</td>\n",
       "      <td>-0.109759</td>\n",
       "      <td>0.299801</td>\n",
       "      <td>-0.116209</td>\n",
       "      <td>0.293351</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115668</td>\n",
       "      <td>0.293892</td>\n",
       "      <td>-0.126447</td>\n",
       "      <td>0.283113</td>\n",
       "      <td>-0.109922</td>\n",
       "      <td>0.299638</td>\n",
       "      <td>-0.114046</td>\n",
       "      <td>0.295514</td>\n",
       "      <td>-0.108705</td>\n",
       "      <td>0.300855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21446</th>\n",
       "      <td>-0.021237</td>\n",
       "      <td>-0.084329</td>\n",
       "      <td>0.063092</td>\n",
       "      <td>-0.089300</td>\n",
       "      <td>0.068063</td>\n",
       "      <td>-0.059869</td>\n",
       "      <td>0.038632</td>\n",
       "      <td>-0.068227</td>\n",
       "      <td>0.046990</td>\n",
       "      <td>-0.083066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080517</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-0.095513</td>\n",
       "      <td>0.074276</td>\n",
       "      <td>-0.071891</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>-0.069692</td>\n",
       "      <td>0.048455</td>\n",
       "      <td>-0.076898</td>\n",
       "      <td>0.055661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21447</th>\n",
       "      <td>-0.264320</td>\n",
       "      <td>0.053496</td>\n",
       "      <td>0.317816</td>\n",
       "      <td>0.085517</td>\n",
       "      <td>0.349837</td>\n",
       "      <td>0.110497</td>\n",
       "      <td>0.374817</td>\n",
       "      <td>0.090765</td>\n",
       "      <td>0.355085</td>\n",
       "      <td>0.080588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066078</td>\n",
       "      <td>0.330398</td>\n",
       "      <td>0.079077</td>\n",
       "      <td>0.343397</td>\n",
       "      <td>0.085814</td>\n",
       "      <td>0.350134</td>\n",
       "      <td>0.092008</td>\n",
       "      <td>0.356328</td>\n",
       "      <td>0.078314</td>\n",
       "      <td>0.342634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21448</th>\n",
       "      <td>0.060178</td>\n",
       "      <td>-0.109101</td>\n",
       "      <td>0.169279</td>\n",
       "      <td>-0.112426</td>\n",
       "      <td>0.172604</td>\n",
       "      <td>-0.084976</td>\n",
       "      <td>0.145154</td>\n",
       "      <td>-0.094101</td>\n",
       "      <td>0.154279</td>\n",
       "      <td>-0.106060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089148</td>\n",
       "      <td>0.149326</td>\n",
       "      <td>-0.100420</td>\n",
       "      <td>0.160598</td>\n",
       "      <td>-0.079930</td>\n",
       "      <td>0.140108</td>\n",
       "      <td>-0.080294</td>\n",
       "      <td>0.140472</td>\n",
       "      <td>-0.078942</td>\n",
       "      <td>0.139120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21449</th>\n",
       "      <td>0.535320</td>\n",
       "      <td>0.217218</td>\n",
       "      <td>0.318102</td>\n",
       "      <td>0.263642</td>\n",
       "      <td>0.271678</td>\n",
       "      <td>0.310424</td>\n",
       "      <td>0.224896</td>\n",
       "      <td>0.223642</td>\n",
       "      <td>0.311678</td>\n",
       "      <td>0.245821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277712</td>\n",
       "      <td>0.257608</td>\n",
       "      <td>0.225980</td>\n",
       "      <td>0.309340</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.251987</td>\n",
       "      <td>0.331273</td>\n",
       "      <td>0.204047</td>\n",
       "      <td>0.269961</td>\n",
       "      <td>0.265359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21450</th>\n",
       "      <td>0.036212</td>\n",
       "      <td>0.020867</td>\n",
       "      <td>0.015345</td>\n",
       "      <td>0.046822</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>0.078560</td>\n",
       "      <td>0.042348</td>\n",
       "      <td>0.050051</td>\n",
       "      <td>0.013839</td>\n",
       "      <td>0.041842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034573</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.042956</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>0.051134</td>\n",
       "      <td>0.014922</td>\n",
       "      <td>0.057315</td>\n",
       "      <td>0.021103</td>\n",
       "      <td>0.044898</td>\n",
       "      <td>0.008686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21451 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Acceleration3        m1      res1        m2      res2        m3  \\\n",
       "0          -0.314890 -0.106363  0.208527 -0.107560  0.207330 -0.080738   \n",
       "1          -0.267150 -0.335971  0.068821 -0.416756  0.149606 -0.308923   \n",
       "2           0.257710  0.242710  0.015000  0.289920  0.032210  0.337488   \n",
       "3          -0.193330 -0.102681  0.090649 -0.100139  0.093191 -0.074237   \n",
       "4          -0.409560 -0.135525  0.274035 -0.139184  0.270376 -0.109759   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "21446      -0.021237 -0.084329  0.063092 -0.089300  0.068063 -0.059869   \n",
       "21447      -0.264320  0.053496  0.317816  0.085517  0.349837  0.110497   \n",
       "21448       0.060178 -0.109101  0.169279 -0.112426  0.172604 -0.084976   \n",
       "21449       0.535320  0.217218  0.318102  0.263642  0.271678  0.310424   \n",
       "21450       0.036212  0.020867  0.015345  0.046822  0.010610  0.078560   \n",
       "\n",
       "           res3        m4      res4        m5  ...      m246    res246  \\\n",
       "0      0.234152 -0.092641  0.222249 -0.106148  ... -0.088585  0.226305   \n",
       "1      0.041773 -0.328997  0.061847 -0.291686  ... -0.261380  0.005770   \n",
       "2      0.079778  0.250313  0.007397  0.272763  ...  0.325091  0.067381   \n",
       "3      0.119093 -0.085076  0.108254 -0.104071  ... -0.108305  0.085025   \n",
       "4      0.299801 -0.116209  0.293351 -0.128368  ... -0.115668  0.293892   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "21446  0.038632 -0.068227  0.046990 -0.083066  ... -0.080517  0.059280   \n",
       "21447  0.374817  0.090765  0.355085  0.080588  ...  0.066078  0.330398   \n",
       "21448  0.145154 -0.094101  0.154279 -0.106060  ... -0.089148  0.149326   \n",
       "21449  0.224896  0.223642  0.311678  0.245821  ...  0.277712  0.257608   \n",
       "21450  0.042348  0.050051  0.013839  0.041842  ...  0.034573  0.001639   \n",
       "\n",
       "           m247    res247      m248    res248      m249    res249      m250  \\\n",
       "0     -0.128249  0.186641 -0.079163  0.235727 -0.079369  0.235521 -0.078189   \n",
       "1     -0.283757  0.016607 -0.262028  0.005122 -0.312943  0.045793 -0.260745   \n",
       "2      0.252545  0.005165  0.331247  0.073537  0.394625  0.136915  0.320211   \n",
       "3     -0.124479  0.068851 -0.093893  0.099437 -0.094721  0.098609 -0.095860   \n",
       "4     -0.126447  0.283113 -0.109922  0.299638 -0.114046  0.295514 -0.108705   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "21446 -0.095513  0.074276 -0.071891  0.050654 -0.069692  0.048455 -0.076898   \n",
       "21447  0.079077  0.343397  0.085814  0.350134  0.092008  0.356328  0.078314   \n",
       "21448 -0.100420  0.160598 -0.079930  0.140108 -0.080294  0.140472 -0.078942   \n",
       "21449  0.225980  0.309340  0.283333  0.251987  0.331273  0.204047  0.269961   \n",
       "21450  0.042956  0.006744  0.051134  0.014922  0.057315  0.021103  0.044898   \n",
       "\n",
       "         res250  \n",
       "0      0.236701  \n",
       "1      0.006405  \n",
       "2      0.062501  \n",
       "3      0.097470  \n",
       "4      0.300855  \n",
       "...         ...  \n",
       "21446  0.055661  \n",
       "21447  0.342634  \n",
       "21448  0.139120  \n",
       "21449  0.265359  \n",
       "21450  0.008686  \n",
       "\n",
       "[21451 rows x 501 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce845589",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-93ffb6aabd9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Nifty call to confirm our variables were properly inputted into our model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   2475\u001b[0m     \"\"\"\n\u001b[0;32m   2476\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2477\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   2478\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2479\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "#Nifty call to confirm our variables were properly inputted into our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac307516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_num</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>time</th>\n",
       "      <th>epochs</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>max_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:06:58.600213</td>\n",
       "      <td>133</td>\n",
       "      <td>0.186559</td>\n",
       "      <td>0.231756</td>\n",
       "      <td>0.217424</td>\n",
       "      <td>0.466287</td>\n",
       "      <td>5.227035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:01:52.498483</td>\n",
       "      <td>36</td>\n",
       "      <td>0.181425</td>\n",
       "      <td>0.232965</td>\n",
       "      <td>0.218796</td>\n",
       "      <td>0.467756</td>\n",
       "      <td>5.223996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:02:09.278538</td>\n",
       "      <td>41</td>\n",
       "      <td>0.188748</td>\n",
       "      <td>0.231858</td>\n",
       "      <td>0.216839</td>\n",
       "      <td>0.465659</td>\n",
       "      <td>5.197324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:05:06.451410</td>\n",
       "      <td>97</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.229295</td>\n",
       "      <td>0.216638</td>\n",
       "      <td>0.465444</td>\n",
       "      <td>5.207352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:04:46.452250</td>\n",
       "      <td>92</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>0.228036</td>\n",
       "      <td>0.215824</td>\n",
       "      <td>0.464569</td>\n",
       "      <td>5.226808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>246</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:02:03.743139</td>\n",
       "      <td>50</td>\n",
       "      <td>0.191273</td>\n",
       "      <td>0.230419</td>\n",
       "      <td>0.216164</td>\n",
       "      <td>0.464934</td>\n",
       "      <td>5.230475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>247</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:02:23.196040</td>\n",
       "      <td>58</td>\n",
       "      <td>0.192038</td>\n",
       "      <td>0.227559</td>\n",
       "      <td>0.215959</td>\n",
       "      <td>0.464714</td>\n",
       "      <td>5.246212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>248</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:01:34.966605</td>\n",
       "      <td>38</td>\n",
       "      <td>0.191216</td>\n",
       "      <td>0.230462</td>\n",
       "      <td>0.216179</td>\n",
       "      <td>0.464951</td>\n",
       "      <td>5.216463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>249</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:01:11.746546</td>\n",
       "      <td>29</td>\n",
       "      <td>0.184985</td>\n",
       "      <td>0.233981</td>\n",
       "      <td>0.217844</td>\n",
       "      <td>0.466738</td>\n",
       "      <td>5.217321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>250</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:02:08.018930</td>\n",
       "      <td>52</td>\n",
       "      <td>0.191255</td>\n",
       "      <td>0.230279</td>\n",
       "      <td>0.216169</td>\n",
       "      <td>0.464939</td>\n",
       "      <td>5.218469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_num           loss_type            time epochs        r2       mae  \\\n",
       "0           1  mean_squared_error  0:06:58.600213    133  0.186559  0.231756   \n",
       "1           2  mean_squared_error  0:01:52.498483     36  0.181425  0.232965   \n",
       "2           3  mean_squared_error  0:02:09.278538     41  0.188748  0.231858   \n",
       "3           4  mean_squared_error  0:05:06.451410     97  0.189500  0.229295   \n",
       "4           5  mean_squared_error  0:04:46.452250     92  0.192543  0.228036   \n",
       "..        ...                 ...             ...    ...       ...       ...   \n",
       "245       246  mean_squared_error  0:02:03.743139     50  0.191273  0.230419   \n",
       "246       247  mean_squared_error  0:02:23.196040     58  0.192038  0.227559   \n",
       "247       248  mean_squared_error  0:01:34.966605     38  0.191216  0.230462   \n",
       "248       249  mean_squared_error  0:01:11.746546     29  0.184985  0.233981   \n",
       "249       250  mean_squared_error  0:02:08.018930     52  0.191255  0.230279   \n",
       "\n",
       "          mse      rmse  max_error  \n",
       "0    0.217424  0.466287   5.227035  \n",
       "1    0.218796  0.467756   5.223996  \n",
       "2    0.216839  0.465659   5.197324  \n",
       "3    0.216638  0.465444   5.207352  \n",
       "4    0.215824  0.464569   5.226808  \n",
       "..        ...       ...        ...  \n",
       "245  0.216164  0.464934   5.230475  \n",
       "246  0.215959  0.464714   5.246212  \n",
       "247  0.216179  0.464951   5.216463  \n",
       "248  0.217844  0.466738   5.217321  \n",
       "249  0.216169  0.464939   5.218469  \n",
       "\n",
       "[250 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "296f1bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acceleration3</th>\n",
       "      <th>m1</th>\n",
       "      <th>res1</th>\n",
       "      <th>m2</th>\n",
       "      <th>res2</th>\n",
       "      <th>m3</th>\n",
       "      <th>res3</th>\n",
       "      <th>m4</th>\n",
       "      <th>res4</th>\n",
       "      <th>m5</th>\n",
       "      <th>...</th>\n",
       "      <th>m246</th>\n",
       "      <th>res246</th>\n",
       "      <th>m247</th>\n",
       "      <th>res247</th>\n",
       "      <th>m248</th>\n",
       "      <th>res248</th>\n",
       "      <th>m249</th>\n",
       "      <th>res249</th>\n",
       "      <th>m250</th>\n",
       "      <th>res250</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.314890</td>\n",
       "      <td>-0.106363</td>\n",
       "      <td>0.208527</td>\n",
       "      <td>-0.107560</td>\n",
       "      <td>0.207330</td>\n",
       "      <td>-0.080738</td>\n",
       "      <td>0.234152</td>\n",
       "      <td>-0.092641</td>\n",
       "      <td>0.222249</td>\n",
       "      <td>-0.106148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088585</td>\n",
       "      <td>0.226305</td>\n",
       "      <td>-0.128249</td>\n",
       "      <td>0.186641</td>\n",
       "      <td>-0.079163</td>\n",
       "      <td>0.235727</td>\n",
       "      <td>-0.079369</td>\n",
       "      <td>0.235521</td>\n",
       "      <td>-0.078189</td>\n",
       "      <td>0.236701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.267150</td>\n",
       "      <td>-0.335971</td>\n",
       "      <td>0.068821</td>\n",
       "      <td>-0.416756</td>\n",
       "      <td>0.149606</td>\n",
       "      <td>-0.308923</td>\n",
       "      <td>0.041773</td>\n",
       "      <td>-0.328997</td>\n",
       "      <td>0.061847</td>\n",
       "      <td>-0.291686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.261380</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>-0.283757</td>\n",
       "      <td>0.016607</td>\n",
       "      <td>-0.262028</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>-0.312943</td>\n",
       "      <td>0.045793</td>\n",
       "      <td>-0.260745</td>\n",
       "      <td>0.006405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.257710</td>\n",
       "      <td>0.242710</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.289920</td>\n",
       "      <td>0.032210</td>\n",
       "      <td>0.337488</td>\n",
       "      <td>0.079778</td>\n",
       "      <td>0.250313</td>\n",
       "      <td>0.007397</td>\n",
       "      <td>0.272763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325091</td>\n",
       "      <td>0.067381</td>\n",
       "      <td>0.252545</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>0.331247</td>\n",
       "      <td>0.073537</td>\n",
       "      <td>0.394625</td>\n",
       "      <td>0.136915</td>\n",
       "      <td>0.320211</td>\n",
       "      <td>0.062501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.193330</td>\n",
       "      <td>-0.102681</td>\n",
       "      <td>0.090649</td>\n",
       "      <td>-0.100139</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>-0.074237</td>\n",
       "      <td>0.119093</td>\n",
       "      <td>-0.085076</td>\n",
       "      <td>0.108254</td>\n",
       "      <td>-0.104071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108305</td>\n",
       "      <td>0.085025</td>\n",
       "      <td>-0.124479</td>\n",
       "      <td>0.068851</td>\n",
       "      <td>-0.093893</td>\n",
       "      <td>0.099437</td>\n",
       "      <td>-0.094721</td>\n",
       "      <td>0.098609</td>\n",
       "      <td>-0.095860</td>\n",
       "      <td>0.097470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.409560</td>\n",
       "      <td>-0.135525</td>\n",
       "      <td>0.274035</td>\n",
       "      <td>-0.139184</td>\n",
       "      <td>0.270376</td>\n",
       "      <td>-0.109759</td>\n",
       "      <td>0.299801</td>\n",
       "      <td>-0.116209</td>\n",
       "      <td>0.293351</td>\n",
       "      <td>-0.128368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115668</td>\n",
       "      <td>0.293892</td>\n",
       "      <td>-0.126447</td>\n",
       "      <td>0.283113</td>\n",
       "      <td>-0.109922</td>\n",
       "      <td>0.299638</td>\n",
       "      <td>-0.114046</td>\n",
       "      <td>0.295514</td>\n",
       "      <td>-0.108705</td>\n",
       "      <td>0.300855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21446</th>\n",
       "      <td>-0.021237</td>\n",
       "      <td>-0.084329</td>\n",
       "      <td>0.063092</td>\n",
       "      <td>-0.089300</td>\n",
       "      <td>0.068063</td>\n",
       "      <td>-0.059869</td>\n",
       "      <td>0.038632</td>\n",
       "      <td>-0.068227</td>\n",
       "      <td>0.046990</td>\n",
       "      <td>-0.083066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080517</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>-0.095513</td>\n",
       "      <td>0.074276</td>\n",
       "      <td>-0.071891</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>-0.069692</td>\n",
       "      <td>0.048455</td>\n",
       "      <td>-0.076898</td>\n",
       "      <td>0.055661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21447</th>\n",
       "      <td>-0.264320</td>\n",
       "      <td>0.053496</td>\n",
       "      <td>0.317816</td>\n",
       "      <td>0.085517</td>\n",
       "      <td>0.349837</td>\n",
       "      <td>0.110497</td>\n",
       "      <td>0.374817</td>\n",
       "      <td>0.090765</td>\n",
       "      <td>0.355085</td>\n",
       "      <td>0.080588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066078</td>\n",
       "      <td>0.330398</td>\n",
       "      <td>0.079077</td>\n",
       "      <td>0.343397</td>\n",
       "      <td>0.085814</td>\n",
       "      <td>0.350134</td>\n",
       "      <td>0.092008</td>\n",
       "      <td>0.356328</td>\n",
       "      <td>0.078314</td>\n",
       "      <td>0.342634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21448</th>\n",
       "      <td>0.060178</td>\n",
       "      <td>-0.109101</td>\n",
       "      <td>0.169279</td>\n",
       "      <td>-0.112426</td>\n",
       "      <td>0.172604</td>\n",
       "      <td>-0.084976</td>\n",
       "      <td>0.145154</td>\n",
       "      <td>-0.094101</td>\n",
       "      <td>0.154279</td>\n",
       "      <td>-0.106060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089148</td>\n",
       "      <td>0.149326</td>\n",
       "      <td>-0.100420</td>\n",
       "      <td>0.160598</td>\n",
       "      <td>-0.079930</td>\n",
       "      <td>0.140108</td>\n",
       "      <td>-0.080294</td>\n",
       "      <td>0.140472</td>\n",
       "      <td>-0.078942</td>\n",
       "      <td>0.139120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21449</th>\n",
       "      <td>0.535320</td>\n",
       "      <td>0.217218</td>\n",
       "      <td>0.318102</td>\n",
       "      <td>0.263642</td>\n",
       "      <td>0.271678</td>\n",
       "      <td>0.310424</td>\n",
       "      <td>0.224896</td>\n",
       "      <td>0.223642</td>\n",
       "      <td>0.311678</td>\n",
       "      <td>0.245821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277712</td>\n",
       "      <td>0.257608</td>\n",
       "      <td>0.225980</td>\n",
       "      <td>0.309340</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.251987</td>\n",
       "      <td>0.331273</td>\n",
       "      <td>0.204047</td>\n",
       "      <td>0.269961</td>\n",
       "      <td>0.265359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21450</th>\n",
       "      <td>0.036212</td>\n",
       "      <td>0.020867</td>\n",
       "      <td>0.015345</td>\n",
       "      <td>0.046822</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>0.078560</td>\n",
       "      <td>0.042348</td>\n",
       "      <td>0.050051</td>\n",
       "      <td>0.013839</td>\n",
       "      <td>0.041842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034573</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.042956</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>0.051134</td>\n",
       "      <td>0.014922</td>\n",
       "      <td>0.057315</td>\n",
       "      <td>0.021103</td>\n",
       "      <td>0.044898</td>\n",
       "      <td>0.008686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21451 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Acceleration3        m1      res1        m2      res2        m3  \\\n",
       "0          -0.314890 -0.106363  0.208527 -0.107560  0.207330 -0.080738   \n",
       "1          -0.267150 -0.335971  0.068821 -0.416756  0.149606 -0.308923   \n",
       "2           0.257710  0.242710  0.015000  0.289920  0.032210  0.337488   \n",
       "3          -0.193330 -0.102681  0.090649 -0.100139  0.093191 -0.074237   \n",
       "4          -0.409560 -0.135525  0.274035 -0.139184  0.270376 -0.109759   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "21446      -0.021237 -0.084329  0.063092 -0.089300  0.068063 -0.059869   \n",
       "21447      -0.264320  0.053496  0.317816  0.085517  0.349837  0.110497   \n",
       "21448       0.060178 -0.109101  0.169279 -0.112426  0.172604 -0.084976   \n",
       "21449       0.535320  0.217218  0.318102  0.263642  0.271678  0.310424   \n",
       "21450       0.036212  0.020867  0.015345  0.046822  0.010610  0.078560   \n",
       "\n",
       "           res3        m4      res4        m5  ...      m246    res246  \\\n",
       "0      0.234152 -0.092641  0.222249 -0.106148  ... -0.088585  0.226305   \n",
       "1      0.041773 -0.328997  0.061847 -0.291686  ... -0.261380  0.005770   \n",
       "2      0.079778  0.250313  0.007397  0.272763  ...  0.325091  0.067381   \n",
       "3      0.119093 -0.085076  0.108254 -0.104071  ... -0.108305  0.085025   \n",
       "4      0.299801 -0.116209  0.293351 -0.128368  ... -0.115668  0.293892   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "21446  0.038632 -0.068227  0.046990 -0.083066  ... -0.080517  0.059280   \n",
       "21447  0.374817  0.090765  0.355085  0.080588  ...  0.066078  0.330398   \n",
       "21448  0.145154 -0.094101  0.154279 -0.106060  ... -0.089148  0.149326   \n",
       "21449  0.224896  0.223642  0.311678  0.245821  ...  0.277712  0.257608   \n",
       "21450  0.042348  0.050051  0.013839  0.041842  ...  0.034573  0.001639   \n",
       "\n",
       "           m247    res247      m248    res248      m249    res249      m250  \\\n",
       "0     -0.128249  0.186641 -0.079163  0.235727 -0.079369  0.235521 -0.078189   \n",
       "1     -0.283757  0.016607 -0.262028  0.005122 -0.312943  0.045793 -0.260745   \n",
       "2      0.252545  0.005165  0.331247  0.073537  0.394625  0.136915  0.320211   \n",
       "3     -0.124479  0.068851 -0.093893  0.099437 -0.094721  0.098609 -0.095860   \n",
       "4     -0.126447  0.283113 -0.109922  0.299638 -0.114046  0.295514 -0.108705   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "21446 -0.095513  0.074276 -0.071891  0.050654 -0.069692  0.048455 -0.076898   \n",
       "21447  0.079077  0.343397  0.085814  0.350134  0.092008  0.356328  0.078314   \n",
       "21448 -0.100420  0.160598 -0.079930  0.140108 -0.080294  0.140472 -0.078942   \n",
       "21449  0.225980  0.309340  0.283333  0.251987  0.331273  0.204047  0.269961   \n",
       "21450  0.042956  0.006744  0.051134  0.014922  0.057315  0.021103  0.044898   \n",
       "\n",
       "         res250  \n",
       "0      0.236701  \n",
       "1      0.006405  \n",
       "2      0.062501  \n",
       "3      0.097470  \n",
       "4      0.300855  \n",
       "...         ...  \n",
       "21446  0.055661  \n",
       "21447  0.342634  \n",
       "21448  0.139120  \n",
       "21449  0.265359  \n",
       "21450  0.008686  \n",
       "\n",
       "[21451 rows x 501 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4067b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_record.to_csv('data/rnn_results_8_2.csv', index = False)\n",
    "predict_record.to_csv('data/rnn_predictions_8_2.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
