{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moving-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime \n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "absolute-lyric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hearing-favorite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices(device_type = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "legislative-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "f16_l3 = pd.read_csv('data/f16_l3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a49c67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = f16_l3['Force']\n",
    "y = f16_l3['Acceleration3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "musical-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_true, y_train, y_true = train_test_split(\n",
    "    X, y, random_state = 8669, test_size = 0.20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "874b8b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare the number of model iterations we will run \n",
    "test_iterations = 5\n",
    "\n",
    "#Declare the number of hidden layers to add\n",
    "layers = 3\n",
    "\n",
    "#Declare the density of the hidden layers\n",
    "density = 128\n",
    "\n",
    "#Declare the type of activation for the hidden layers\n",
    "activation = 'relu'\n",
    "\n",
    "#Assign the loss function the model will use to train\n",
    "loss = 'mean_squared_error'\n",
    "\n",
    "#Declare the batch size for use in the model\n",
    "batch_size = 64\n",
    "\n",
    "#Declare the maximum number of epochs for our model\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bronze-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigns the computation to be performed via GPU Device:0\n",
    "with tf.device('/gpu:0'):\n",
    "    model = Sequential()\n",
    "\n",
    "    #Creates a for loop that will add the number of layers based on the variable declared in the previous cell    \n",
    "    for i in range(layers):\n",
    "        #Adds a model layer with density and activation based on the variables declared in the previous cell\n",
    "        model.add(Dense(density, activation = activation))\n",
    "    \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss = loss, optimizer = 'adam', metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "detailed-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#es = EarlyStopping(monitor = 'loss', patience = 25, restore_best_weights = True)\n",
    "#mc = ModelCheckpoint(filepath = 'test_model.h5', monitor = 'loss', save_best_only=True)\n",
    "#X_es_train, X_es_test, y_es_train, y_es_test = train_test_split(X_train, y_train, test_size = 0.25, random_state = 8669)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7cdf4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a dataframe by which we will eventually put in our list created above\n",
    "model_record = pd.DataFrame(columns = ['model_num', 'loss_type', 'time', 'r2', 'mae', 'mse', 'rmse', 'max_error'])\n",
    "\n",
    "#Creates a dataframe by which our model's predicted values and true values will be stored\n",
    "predict_record = pd.DataFrame(y_true).reset_index(drop = True)\n",
    "\n",
    "#Creates a numpy array by which the for loop will use to count model runs and is then used to name df columns\n",
    "model_counter = np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "098002c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1341/1341 [==============================] - 4s 3ms/step - loss: 0.2412 - mse: 0.2412\n",
      "Epoch 2/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2313 - mse: 0.2313\n",
      "Epoch 3/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2305 - mse: 0.2305\n",
      "Epoch 4/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2285 - mse: 0.2285\n",
      "Epoch 5/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2268 - mse: 0.2268\n",
      "Epoch 6/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2250 - mse: 0.2250\n",
      "Epoch 7/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2225 - mse: 0.2225\n",
      "Epoch 8/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2200 - mse: 0.2200\n",
      "Epoch 9/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2187 - mse: 0.2187\n",
      "Epoch 10/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2169 - mse: 0.2169\n",
      "Epoch 11/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2163 - mse: 0.2163\n",
      "Epoch 12/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2149 - mse: 0.2149\n",
      "Epoch 13/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2156 - mse: 0.2156\n",
      "Epoch 14/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2155 - mse: 0.2155\n",
      "Epoch 15/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2153 - mse: 0.2153\n",
      "Epoch 16/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2144 - mse: 0.2144\n",
      "Epoch 17/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2134 - mse: 0.2134\n",
      "Epoch 18/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2132 - mse: 0.2132\n",
      "Epoch 19/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2143 - mse: 0.2143\n",
      "Epoch 20/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2125 - mse: 0.2125\n",
      "Epoch 21/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2133 - mse: 0.2133\n",
      "Epoch 22/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2128 - mse: 0.2128\n",
      "Epoch 23/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2127 - mse: 0.2127\n",
      "Epoch 24/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2126 - mse: 0.2126\n",
      "Epoch 25/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2134 - mse: 0.2134\n",
      "Epoch 1/25\n",
      "1341/1341 [==============================] - 4s 3ms/step - loss: 0.2125 - mse: 0.2125\n",
      "Epoch 2/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2122 - mse: 0.2122\n",
      "Epoch 3/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2119 - mse: 0.2119\n",
      "Epoch 4/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2126 - mse: 0.2126\n",
      "Epoch 5/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2121 - mse: 0.2121\n",
      "Epoch 6/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2122 - mse: 0.2122\n",
      "Epoch 7/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2128 - mse: 0.2128\n",
      "Epoch 8/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2120 - mse: 0.2120\n",
      "Epoch 9/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2119 - mse: 0.2119\n",
      "Epoch 10/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2124 - mse: 0.2124\n",
      "Epoch 11/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2119 - mse: 0.2119\n",
      "Epoch 12/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2126 - mse: 0.2126\n",
      "Epoch 13/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2122 - mse: 0.2122\n",
      "Epoch 14/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2121 - mse: 0.2121\n",
      "Epoch 15/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2122 - mse: 0.2122\n",
      "Epoch 16/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2119 - mse: 0.2119\n",
      "Epoch 17/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2122 - mse: 0.2122\n",
      "Epoch 18/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2120 - mse: 0.2120\n",
      "Epoch 19/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2125 - mse: 0.2125\n",
      "Epoch 20/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2121 - mse: 0.2121\n",
      "Epoch 21/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2117 - mse: 0.2117\n",
      "Epoch 22/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2116 - mse: 0.2116\n",
      "Epoch 23/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2123 - mse: 0.2123\n",
      "Epoch 24/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2123 - mse: 0.2123\n",
      "Epoch 25/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2116 - mse: 0.2116\n",
      "Epoch 1/25\n",
      "1341/1341 [==============================] - 4s 3ms/step - loss: 0.2124 - mse: 0.2124\n",
      "Epoch 2/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2117 - mse: 0.2117\n",
      "Epoch 3/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2115 - mse: 0.2115\n",
      "Epoch 4/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2117 - mse: 0.2117\n",
      "Epoch 5/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2113 - mse: 0.2113\n",
      "Epoch 6/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2117 - mse: 0.2117\n",
      "Epoch 7/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2114 - mse: 0.2114\n",
      "Epoch 8/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2117 - mse: 0.2117\n",
      "Epoch 9/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2117 - mse: 0.2117\n",
      "Epoch 10/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2114 - mse: 0.2114\n",
      "Epoch 11/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2115 - mse: 0.2115\n",
      "Epoch 12/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2112 - mse: 0.2112\n",
      "Epoch 13/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2112 - mse: 0.2112\n",
      "Epoch 14/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2112 - mse: 0.2112\n",
      "Epoch 15/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2113 - mse: 0.2113\n",
      "Epoch 16/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2112 - mse: 0.2112\n",
      "Epoch 17/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2112 - mse: 0.2112\n",
      "Epoch 18/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2114 - mse: 0.2114\n",
      "Epoch 19/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2115 - mse: 0.2115\n",
      "Epoch 20/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2112 - mse: 0.2112\n",
      "Epoch 21/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2111 - mse: 0.2111\n",
      "Epoch 22/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2113 - mse: 0.2113\n",
      "Epoch 23/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2111 - mse: 0.2111\n",
      "Epoch 24/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2111 - mse: 0.2111\n",
      "Epoch 25/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2113 - mse: 0.2113\n",
      "Epoch 1/25\n",
      "1341/1341 [==============================] - 4s 2ms/step - loss: 0.2112 - mse: 0.2112\n",
      "Epoch 2/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2113 - mse: 0.2113\n",
      "Epoch 3/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2112 - mse: 0.2112\n",
      "Epoch 4/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2112 - mse: 0.2112\n",
      "Epoch 5/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2113 - mse: 0.2113\n",
      "Epoch 6/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2110 - mse: 0.2110\n",
      "Epoch 7/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2110 - mse: 0.2110\n",
      "Epoch 8/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2113 - mse: 0.2113\n",
      "Epoch 9/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2109 - mse: 0.2109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2111 - mse: 0.2111\n",
      "Epoch 11/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2111 - mse: 0.2111\n",
      "Epoch 12/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2110 - mse: 0.2110\n",
      "Epoch 13/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2110 - mse: 0.2110\n",
      "Epoch 14/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2109 - mse: 0.2109\n",
      "Epoch 15/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2110 - mse: 0.2110\n",
      "Epoch 16/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2111 - mse: 0.2111\n",
      "Epoch 17/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2110 - mse: 0.2110\n",
      "Epoch 18/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2110 - mse: 0.2110\n",
      "Epoch 19/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2109 - mse: 0.2109\n",
      "Epoch 20/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2109 - mse: 0.2109\n",
      "Epoch 21/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2110 - mse: 0.2110\n",
      "Epoch 22/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2112 - mse: 0.2112\n",
      "Epoch 23/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2107 - mse: 0.2107\n",
      "Epoch 24/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2111 - mse: 0.2111\n",
      "Epoch 25/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2110 - mse: 0.2110\n",
      "Epoch 1/25\n",
      "1341/1341 [==============================] - 4s 2ms/step - loss: 0.2111 - mse: 0.2111\n",
      "Epoch 2/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2109 - mse: 0.2109\n",
      "Epoch 3/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2110 - mse: 0.2110\n",
      "Epoch 4/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2110 - mse: 0.2110\n",
      "Epoch 5/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2110 - mse: 0.2110\n",
      "Epoch 6/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2109 - mse: 0.2109\n",
      "Epoch 7/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2109 - mse: 0.2109\n",
      "Epoch 8/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2109 - mse: 0.2109\n",
      "Epoch 9/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2106 - mse: 0.2106\n",
      "Epoch 10/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2109 - mse: 0.2109\n",
      "Epoch 11/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2110 - mse: 0.2110\n",
      "Epoch 12/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2108 - mse: 0.2108\n",
      "Epoch 13/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2106 - mse: 0.2106\n",
      "Epoch 14/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2109 - mse: 0.2109\n",
      "Epoch 15/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2110 - mse: 0.2110\n",
      "Epoch 16/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2110 - mse: 0.2110\n",
      "Epoch 17/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2107 - mse: 0.2107\n",
      "Epoch 18/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2109 - mse: 0.2109\n",
      "Epoch 19/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2107 - mse: 0.2107\n",
      "Epoch 20/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2107 - mse: 0.2107\n",
      "Epoch 21/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2108 - mse: 0.2108\n",
      "Epoch 22/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2107 - mse: 0.2107\n",
      "Epoch 23/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2109 - mse: 0.2109\n",
      "Epoch 24/25\n",
      "1341/1341 [==============================] - 3s 3ms/step - loss: 0.2110 - mse: 0.2110\n",
      "Epoch 25/25\n",
      "1341/1341 [==============================] - 3s 2ms/step - loss: 0.2105 - mse: 0.2105\n"
     ]
    }
   ],
   "source": [
    "#Assigns the computation to be performed via GPU Device:0\n",
    "with tf.device('/gpu:0'):\n",
    "    \n",
    "#Performs model training repeatedly based on the variable declared previously    \n",
    "    for i in range(test_iterations):\n",
    "        model.compile(loss = loss, optimizer = 'adam', metrics = ['mse'])\n",
    "\n",
    "        #Creates an empty list for storing model metrics and other information \n",
    "        record_list = list() \n",
    "        #Starts a counter that adds 1 everytime a fitting is performed\n",
    "        model_counter = model_counter + 1\n",
    "        #Starts a timer to end after the round of fitting is complete\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        #Fits our model/batch_size and epochs are declared previously\n",
    "        model.fit(x = X_train, y = y_train.values, \n",
    "                  batch_size = batch_size, epochs = epochs)\n",
    "        \n",
    "        #Saves our model predictions\n",
    "        y_pred = model.predict(X_true)\n",
    "        \n",
    "        #Saves our model run #, time to run, and model metrics to our temporary list\n",
    "        record_list.extend([len(model_record)+1,\n",
    "                            loss, \n",
    "                            format(datetime.now() - start_time),\n",
    "                            r2_score(y_true, y_pred),\n",
    "                            mean_absolute_error(y_true, y_pred), \n",
    "                            mean_squared_error(y_true, y_pred), \n",
    "                            np.sqrt(mean_squared_error(y_true, y_pred)), \n",
    "                            max_error(y_true, y_pred)\n",
    "                           ])        \n",
    "        \n",
    "        #Adds the temporary list of model metrics (etc) to the end of a dataframe\n",
    "        model_record.loc[len(model_record)] = record_list\n",
    "        \n",
    "        #Converts our predictions to a dataframe so it will play nice\n",
    "        y_pred_df = pd.DataFrame(y_pred)\n",
    "        \n",
    "        #Adds predictions as a column to the end of a dataframe and names is accordingly\n",
    "        predict_record = pd.concat([predict_record, y_pred_df], axis = 1)\n",
    "        predict_record = predict_record.rename(columns = {0 : 'm' + str(model_counter[0])})\n",
    "        \n",
    "        #Calculates the residual values for each prediction and stores it as a dataframe \n",
    "        residuals_df = pd.DataFrame(abs(predict_record.iloc[:,len(predict_record.columns)-1] - predict_record.iloc[:,0]))\n",
    "        \n",
    "        #Adds y residuals as a column to the end of a dataframe and names is accordingly\n",
    "        predict_record = pd.concat([predict_record, residuals_df], axis = 1)\n",
    "        predict_record = predict_record.rename(columns = {0 : 'res' + str(model_counter[0])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "affa6aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_num</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>time</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>max_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:01:25.540956</td>\n",
       "      <td>0.175961</td>\n",
       "      <td>0.236676</td>\n",
       "      <td>0.220256</td>\n",
       "      <td>0.469315</td>\n",
       "      <td>5.210990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:01:25.221900</td>\n",
       "      <td>0.191097</td>\n",
       "      <td>0.230083</td>\n",
       "      <td>0.216211</td>\n",
       "      <td>0.464985</td>\n",
       "      <td>5.221564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:01:24.890342</td>\n",
       "      <td>0.188375</td>\n",
       "      <td>0.228877</td>\n",
       "      <td>0.216938</td>\n",
       "      <td>0.465766</td>\n",
       "      <td>5.229677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:01:23.352573</td>\n",
       "      <td>0.188535</td>\n",
       "      <td>0.229859</td>\n",
       "      <td>0.216896</td>\n",
       "      <td>0.465720</td>\n",
       "      <td>5.221913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>0:01:23.310065</td>\n",
       "      <td>0.188981</td>\n",
       "      <td>0.229496</td>\n",
       "      <td>0.216776</td>\n",
       "      <td>0.465592</td>\n",
       "      <td>5.229672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_num           loss_type            time        r2       mae       mse  \\\n",
       "0         1  mean_squared_error  0:01:25.540956  0.175961  0.236676  0.220256   \n",
       "1         2  mean_squared_error  0:01:25.221900  0.191097  0.230083  0.216211   \n",
       "2         3  mean_squared_error  0:01:24.890342  0.188375  0.228877  0.216938   \n",
       "3         4  mean_squared_error  0:01:23.352573  0.188535  0.229859  0.216896   \n",
       "4         5  mean_squared_error  0:01:23.310065  0.188981  0.229496  0.216776   \n",
       "\n",
       "       rmse  max_error  \n",
       "0  0.469315   5.210990  \n",
       "1  0.464985   5.221564  \n",
       "2  0.465766   5.229677  \n",
       "3  0.465720   5.221913  \n",
       "4  0.465592   5.229672  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "welsh-posting",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acceleration3</th>\n",
       "      <th>m1</th>\n",
       "      <th>res1</th>\n",
       "      <th>m2</th>\n",
       "      <th>res2</th>\n",
       "      <th>m3</th>\n",
       "      <th>res3</th>\n",
       "      <th>m4</th>\n",
       "      <th>res4</th>\n",
       "      <th>m5</th>\n",
       "      <th>res5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.314890</td>\n",
       "      <td>-0.089449</td>\n",
       "      <td>0.225441</td>\n",
       "      <td>-0.091243</td>\n",
       "      <td>0.223647</td>\n",
       "      <td>-0.095828</td>\n",
       "      <td>0.219062</td>\n",
       "      <td>-0.091402</td>\n",
       "      <td>0.223488</td>\n",
       "      <td>-0.107472</td>\n",
       "      <td>0.207418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.267150</td>\n",
       "      <td>-0.259260</td>\n",
       "      <td>0.007890</td>\n",
       "      <td>-0.281525</td>\n",
       "      <td>0.014375</td>\n",
       "      <td>-0.285917</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>-0.284322</td>\n",
       "      <td>0.017172</td>\n",
       "      <td>-0.263090</td>\n",
       "      <td>0.004060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.257710</td>\n",
       "      <td>0.429471</td>\n",
       "      <td>0.171761</td>\n",
       "      <td>0.348689</td>\n",
       "      <td>0.090979</td>\n",
       "      <td>0.248473</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.254558</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>0.311853</td>\n",
       "      <td>0.054143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.193330</td>\n",
       "      <td>-0.086444</td>\n",
       "      <td>0.106886</td>\n",
       "      <td>-0.094211</td>\n",
       "      <td>0.099119</td>\n",
       "      <td>-0.101668</td>\n",
       "      <td>0.091662</td>\n",
       "      <td>-0.095872</td>\n",
       "      <td>0.097458</td>\n",
       "      <td>-0.108145</td>\n",
       "      <td>0.085185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.409560</td>\n",
       "      <td>-0.114940</td>\n",
       "      <td>0.294620</td>\n",
       "      <td>-0.115746</td>\n",
       "      <td>0.293814</td>\n",
       "      <td>-0.126082</td>\n",
       "      <td>0.283478</td>\n",
       "      <td>-0.118829</td>\n",
       "      <td>0.290731</td>\n",
       "      <td>-0.127176</td>\n",
       "      <td>0.282384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21446</th>\n",
       "      <td>-0.021237</td>\n",
       "      <td>-0.065375</td>\n",
       "      <td>0.044138</td>\n",
       "      <td>-0.086006</td>\n",
       "      <td>0.064769</td>\n",
       "      <td>-0.082688</td>\n",
       "      <td>0.061451</td>\n",
       "      <td>-0.076541</td>\n",
       "      <td>0.055304</td>\n",
       "      <td>-0.086572</td>\n",
       "      <td>0.065335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21447</th>\n",
       "      <td>-0.264320</td>\n",
       "      <td>0.094339</td>\n",
       "      <td>0.358659</td>\n",
       "      <td>0.079389</td>\n",
       "      <td>0.343709</td>\n",
       "      <td>0.084553</td>\n",
       "      <td>0.348873</td>\n",
       "      <td>0.067561</td>\n",
       "      <td>0.331881</td>\n",
       "      <td>0.066069</td>\n",
       "      <td>0.330389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21448</th>\n",
       "      <td>0.060178</td>\n",
       "      <td>-0.089688</td>\n",
       "      <td>0.149866</td>\n",
       "      <td>-0.093076</td>\n",
       "      <td>0.153254</td>\n",
       "      <td>-0.095743</td>\n",
       "      <td>0.155921</td>\n",
       "      <td>-0.090387</td>\n",
       "      <td>0.150565</td>\n",
       "      <td>-0.105722</td>\n",
       "      <td>0.165900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21449</th>\n",
       "      <td>0.535320</td>\n",
       "      <td>0.402736</td>\n",
       "      <td>0.132584</td>\n",
       "      <td>0.277093</td>\n",
       "      <td>0.258227</td>\n",
       "      <td>0.220593</td>\n",
       "      <td>0.314727</td>\n",
       "      <td>0.226402</td>\n",
       "      <td>0.308918</td>\n",
       "      <td>0.282134</td>\n",
       "      <td>0.253186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21450</th>\n",
       "      <td>0.036212</td>\n",
       "      <td>0.067655</td>\n",
       "      <td>0.031443</td>\n",
       "      <td>0.059951</td>\n",
       "      <td>0.023739</td>\n",
       "      <td>0.057392</td>\n",
       "      <td>0.021180</td>\n",
       "      <td>0.037932</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.029237</td>\n",
       "      <td>0.006975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21451 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Acceleration3        m1      res1        m2      res2        m3  \\\n",
       "0          -0.314890 -0.089449  0.225441 -0.091243  0.223647 -0.095828   \n",
       "1          -0.267150 -0.259260  0.007890 -0.281525  0.014375 -0.285917   \n",
       "2           0.257710  0.429471  0.171761  0.348689  0.090979  0.248473   \n",
       "3          -0.193330 -0.086444  0.106886 -0.094211  0.099119 -0.101668   \n",
       "4          -0.409560 -0.114940  0.294620 -0.115746  0.293814 -0.126082   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "21446      -0.021237 -0.065375  0.044138 -0.086006  0.064769 -0.082688   \n",
       "21447      -0.264320  0.094339  0.358659  0.079389  0.343709  0.084553   \n",
       "21448       0.060178 -0.089688  0.149866 -0.093076  0.153254 -0.095743   \n",
       "21449       0.535320  0.402736  0.132584  0.277093  0.258227  0.220593   \n",
       "21450       0.036212  0.067655  0.031443  0.059951  0.023739  0.057392   \n",
       "\n",
       "           res3        m4      res4        m5      res5  \n",
       "0      0.219062 -0.091402  0.223488 -0.107472  0.207418  \n",
       "1      0.018767 -0.284322  0.017172 -0.263090  0.004060  \n",
       "2      0.009237  0.254558  0.003152  0.311853  0.054143  \n",
       "3      0.091662 -0.095872  0.097458 -0.108145  0.085185  \n",
       "4      0.283478 -0.118829  0.290731 -0.127176  0.282384  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "21446  0.061451 -0.076541  0.055304 -0.086572  0.065335  \n",
       "21447  0.348873  0.067561  0.331881  0.066069  0.330389  \n",
       "21448  0.155921 -0.090387  0.150565 -0.105722  0.165900  \n",
       "21449  0.314727  0.226402  0.308918  0.282134  0.253186  \n",
       "21450  0.021180  0.037932  0.001720  0.029237  0.006975  \n",
       "\n",
       "[21451 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce845589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 33,409\n",
      "Trainable params: 33,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Nifty call to confirm our variables were properly inputted into our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4067b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_record.to_csv('data/rnn_results_1.csv')\n",
    "#predict_record.to_csv('data/rnn_predictions_1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
